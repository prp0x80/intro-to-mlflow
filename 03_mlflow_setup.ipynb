{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: MLflow Set Up\n",
    "execute:\n",
    "  echo: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will install MLflow and try out different configuration scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "The easiest way to install MLflow is using `pip` as follows -\n",
    "\n",
    ":::{.callout-note}\n",
    "Make sure you have created and activated the virtual environment using the python virtual environment manager of your choice.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install --quiet mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow comes with a rich CLI that provides a simple interface to various functionality in MLflow. You can use the CLI to run projects, start the tracking UI, create and list experiments, download run artifacts, serve MLflow Python Function and scikit-learn models, and serve models on Microsoft Azure Machine Learning and Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "Options:\n",
      "  --version  Show the version and exit.\n",
      "  --help     Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  artifacts    Upload, list, and download artifacts from an MLflow...\n",
      "  azureml      Serve models on Azure ML.\n",
      "  db           Commands for managing an MLflow tracking database.\n",
      "  deployments  Deploy MLflow models to custom targets.\n",
      "  experiments  Manage experiments.\n",
      "  gc           Permanently delete runs in the `deleted` lifecycle stage.\n",
      "  models       Deploy MLflow models locally.\n",
      "  pipelines    Run MLflow Pipelines and inspect pipeline results.\n",
      "  run          Run an MLflow project from the given URI.\n",
      "  runs         Manage runs.\n",
      "  sagemaker    Serve models on SageMaker.\n",
      "  server       Run the MLflow tracking server.\n",
      "  ui           Launch the MLflow tracking UI for local viewing of run...\n"
     ]
    }
   ],
   "source": [
    "!mlflow --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will use `mlflow server <args>` and `mlflow ui` commands to demonstrate different MLflow set up scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common MLflow configurations\n",
    "\n",
    "Since the MLflow client can interface with a variety of backend and artifact storage configurations. We will look a three common scenarios:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario#1\n",
    "\n",
    "> MLflow on localhost  \n",
    "\n",
    "This is the most basic set up, where both backend and artifact store are set to local file store. It's the default mode, so we don't have to set any parameters while starting the tracking server.  \n",
    "\n",
    "Start MLflow tracking server without any arguments as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "```bash\n",
    "mlflow server\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/scenario1.png){fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario#2\n",
    "\n",
    "> MLflow on localhost with backend store as an SQLAlchemy compatible database type: SQLite\n",
    "\n",
    "In this case, artifacts are stored under a local directory, and MLflow entities are inserted in a SQLite database file `mlruns.db`.\n",
    "\n",
    "Start MLflow tracking server by specifying appropriate values for `--backend-store-uri` and `--default-artifact-root` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "```bash\n",
    "mlflow server --backend-store-uri sqlite:////workspace/mlruns.db \\\n",
    "              --default-artifact-root /workspace/mlruns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/scenario2.png){fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario#3\n",
    "\n",
    "> Tracking server launched at localhost\n",
    "\n",
    "Similar to scenario 1 but a tracking server is launched, listening for REST request calls at the default port 5000.\n",
    "\n",
    "Start MLflow tracking server by specifying local file path value for `--backend-store-uri` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "```bash\n",
    "mlflow server --backend-store-uri /workspace/mlruns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/scenario3.png){fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "To make the CLI commands aware of the tracking server set the `MLFLOW_TRACKING_URI` environment variable as follows:\n",
    "\n",
    "```bash\n",
    "export MLFLOW_TRACKING_URI=\"http://localhost:5000\"\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Tracking UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tracking server is up using the scenario of choice, you can launch MLflow tracking UI by typing `http://localhost:5000` in the browser.  \n",
    "\n",
    "MLFlow Tracking UI is in constant communication with the tracking server to present the results of each experiment from the set storage location.\n",
    "The UI contains the following key features:\n",
    "\n",
    "- Experiment-based run listing and comparison (including run comparison across multiple experiments)\n",
    "- Searching for runs by parameter or metric value\n",
    "- Visualizing run metrics\n",
    "- Downloading run results\n",
    "\n",
    "![](./images/mlflow_ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep-learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "68d036a9b42d5c828d1ba68a8f2ccbe596a4b4792344440f3a0b3ae77071625c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
