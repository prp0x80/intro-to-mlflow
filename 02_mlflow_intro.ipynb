{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  echo: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "fig-cap-location: bottom\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is ML library and language agnostic framework, i.e., it supports all popular ML libraries\n",
    "- It supports both local and cloud development environments\n",
    "- It is simple and modular to use - can be simply infused into existing ML code\n",
    "- It is easy to get started, hence delivers positive developer experience!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "The easiest way to install MLflow is using `pip` as follows -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --quiet mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow comes with a rich CLI that provides a simple interface to various functionality in MLflow. You can use the CLI to run projects, start the tracking UI, create and list experiments, download run artifacts, serve MLflow Python Function and scikit-learn models, and serve models on Microsoft Azure Machine Learning and Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "Options:\n",
      "  --version  Show the version and exit.\n",
      "  --help     Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  artifacts    Upload, list, and download artifacts from an MLflow...\n",
      "  azureml      Serve models on Azure ML.\n",
      "  db           Commands for managing an MLflow tracking database.\n",
      "  deployments  Deploy MLflow models to custom targets.\n",
      "  experiments  Manage experiments.\n",
      "  gc           Permanently delete runs in the `deleted` lifecycle stage.\n",
      "  models       Deploy MLflow models locally.\n",
      "  pipelines    Run MLflow Pipelines and inspect pipeline results.\n",
      "  run          Run an MLflow project from the given URI.\n",
      "  runs         Manage runs.\n",
      "  sagemaker    Serve models on SageMaker.\n",
      "  server       Run the MLflow tracking server.\n",
      "  ui           Launch the MLflow tracking UI for local viewing of run...\n"
     ]
    }
   ],
   "source": [
    "!mlflow --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow currently offers four components:\n",
    "\n",
    "![](./images/mlflow_components.png)\n",
    "\n",
    "::: {.callout-note}\n",
    "MLflow Models and MLflow Registry are not within the scope of this training.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Tracking\n",
    "\n",
    "When you use MLflow model tracking, you can train a variety of different machine learning models then make predictions with them interchangeably using the standardized model prediction interface. You can also register your models in the MLflow model registry and keep track of which model is being used in production so that this information is easily accessible to everyone you are working with.  \n",
    "\n",
    "MLflow Tracking is organized around the concept of `runs`, which are executions of some piece of data science code. Each run records the following information -\n",
    "\n",
    "- `Parameters`: Key-value inputs to your code\n",
    "- `Metrics`: Numeric values (can update over time)\n",
    "- `Tags and Notes`: Additional information about a run\n",
    "- `Artifacts`: Files, data, and models\n",
    "- `Source`: Name of the file used to launch the run\n",
    "- `Version`: The version of the source code\n",
    "- `Run`: An instance of code that runs by MLflow\n",
    "- `Experiment`: {`Run`, ..., `Run`}\n",
    "- `Start & End Time`: Start and end time of a run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/mlflow_experiments.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs and Artifacts Store\n",
    "\n",
    "MLFlow provides wide variety of storage option for logging runs and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLflow Runs\n",
    "\n",
    "- They can be recorded to local files, to a SQLAlchemy compatible database, or remotely to a tracking server.\n",
    "- MLflow uses `backend store` component for storing `runs`\n",
    "- Backend store persists MLflow entities (runs, parameters, metrics, tags, notes, metadata, etc.)\n",
    "- Backend store options:\n",
    "    - A file store backend - local file path\n",
    "    - A database-backed store - `mysql`, `mssql`, `sqlite`, or `postgresql`\n",
    "    - HTTP server (specified as `https://my-server:5000`), which is a server hosting an MLflow tracking server.\n",
    "\n",
    ":::{.callout-note}\n",
    "By default, the MLflow Python API logs runs locally to files in an `mlruns` directory wherever you ran your program. You can then run `mlflow ui` to see the logged runs.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLflow Artifacts\n",
    "\n",
    "- They can be persisted to local files and a variety of remote file storage solutions.\n",
    "- MLflow uses `artifact store` component for storing `artifacts`\n",
    "- Artifact store persists artifacts (files, models, images, in-memory objects, or model summary, etc.)\n",
    "- Artifact store options:\n",
    "    - Local file path\n",
    "    - Amazon S3\n",
    "    - Azure Blob Storage\n",
    "    - Google Cloud Storage\n",
    "    - SFTP Server\n",
    "    - NFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common MLflow configurations\n",
    "\n",
    "Since the MLflow client can interface with a variety of backend and artifact storage configurations. We will look a three common scenarios:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Scenario 1 - MLflow on localhost](./images/scenario1.png){fig-align=\"center\"}\n",
    "\n",
    "![Scenario 2 - MLflow on localhost with backend store as an SQLAlchemy compatible database type: SQLite](./images/scenario2.png){fig-align=\"center\"}\n",
    "\n",
    "![Scenario 3 - Tracking server launched at localhost: mlflow server --backend-store-uri /workspace/mlruns](./images/scenario3.png){fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
