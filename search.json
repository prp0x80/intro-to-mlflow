[
  {
    "objectID": "01_ml_complexities.html#traditional-software-vs.-machine-learning",
    "href": "01_ml_complexities.html#traditional-software-vs.-machine-learning",
    "title": "Data & AI Engineering Academy",
    "section": "Traditional Software vs. Machine Learning",
    "text": "Developing machine learning applications is complex, and the complexity doesn’t necessarity strive from the fact that the theory behind the machine learning is difficult, or the math is difficult or the algorithm which are presented are difficult. Although there is some element of complexity, the machine learning frameworks makes it easier by abstracting away the details and exposing a simple class interface to initialise and train the model. In fact the default paramters gives pretty much a good baseline model to work with.\n\n\n\n\n\n\n\nTraditional Software\nMachine Learning\n\n\n\n\nGoal: Meet a functional specification\nGoal: Optimize metric (e.g. accuracy) Constantly experiment to improve it.\n\n\nQuality depends only on code\nQuality depends on input data and tuning parmeters\n\n\nTypically pick one software stack w/ fewer libraries and tools\nCompare + combine many libraries, models\n\n\nLimited deployment environments\nDiverse deployment environments"
  },
  {
    "objectID": "01_ml_complexities.html#machine-learning-lifecycle",
    "href": "01_ml_complexities.html#machine-learning-lifecycle",
    "title": "Data & AI Engineering Academy",
    "section": "Machine Learning Lifecycle",
    "text": "Following are four stages of a machine learning lifecycle, there can be other stages is between, but these are the paramount stages -\n\nData Ingestion - Depending on the nature of data you might use one of the many data technologies for staging the data e.g., Hadoop, Kafka, S3, Delta lake, etc.\nData Preparation - As per requirement and ease of use you might use a library in different language for preparing the data e.g., Spark, Pandas, Scikit-Learn, R, Java, etc.\nTraining - Depending on the problem and type of data you might use different libraries or framework for training the model e.g., Scikit-Learn, TensorFlow, PyTorch, Xgboost, etc.\nDeployment - Based on the type of model and how you want to serve the results there are many deployment options like Docker, Kubernetes, TensorFlow serving, Flask, etc."
  },
  {
    "objectID": "01_ml_complexities.html#challenges-in-managing-machine-learning-lifecycle",
    "href": "01_ml_complexities.html#challenges-in-managing-machine-learning-lifecycle",
    "title": "Data & AI Engineering Academy",
    "section": "Challenges in managing Machine Learning lifecycle",
    "text": "Each stage has it’s own requirements and tools\nSome stages (data preparation and training) rely on tuning parameters\nEach stage has it’s own scaling requirements\nEnsuring the same model that yielded optimal performance is deployed\nGovernance and provenance - how the model evolved, who used it, when it was used so on and so forth.\n\nTo solve these challenges, MLflow, an open source project, simplifies the entire ML lifecycle. MLflow introduces simple abstractions to package reproducible projects, track results, encapsulate models that can be used with many existing tools, and central repository to share models, accelerating the ML lifecycle for organizations of any size."
  },
  {
    "objectID": "02_mlflow_intro.html#install",
    "href": "02_mlflow_intro.html#install",
    "title": "Data & AI Engineering Academy",
    "section": "Install",
    "text": "The easiest way to install MLflow is using pip as follows -\n!pip install --upgrade pip\n!pip install --quiet mlflow\nMLflow comes with a rich CLI that provides a simple interface to various functionality in MLflow. You can use the CLI to run projects, start the tracking UI, create and list experiments, download run artifacts, serve MLflow Python Function and scikit-learn models, and serve models on Microsoft Azure Machine Learning and Amazon SageMaker.\n\n!mlflow --help\n\nUsage: mlflow [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --version  Show the version and exit.\n  --help     Show this message and exit.\n\nCommands:\n  artifacts    Upload, list, and download artifacts from an MLflow...\n  azureml      Serve models on Azure ML.\n  db           Commands for managing an MLflow tracking database.\n  deployments  Deploy MLflow models to custom targets.\n  experiments  Manage experiments.\n  gc           Permanently delete runs in the `deleted` lifecycle stage.\n  models       Deploy MLflow models locally.\n  pipelines    Run MLflow Pipelines and inspect pipeline results.\n  run          Run an MLflow project from the given URI.\n  runs         Manage runs.\n  sagemaker    Serve models on SageMaker.\n  server       Run the MLflow tracking server.\n  ui           Launch the MLflow tracking UI for local viewing of run..."
  },
  {
    "objectID": "02_mlflow_intro.html#mlflow-components",
    "href": "02_mlflow_intro.html#mlflow-components",
    "title": "Data & AI Engineering Academy",
    "section": "MLflow Components",
    "text": "MLflow currently offers four components:\n\n\n\n\n\n\n\nNote\n\n\n\nMLflow Models and MLflow Registry are not within the scope of this training.\n\n\n\nMLflow Tracking\nWhen you use MLflow model tracking, you can train a variety of different machine learning models then make predictions with them interchangeably using the standardized model prediction interface. You can also register your models in the MLflow model registry and keep track of which model is being used in production so that this information is easily accessible to everyone you are working with.\nMLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code. Each run records the following information -\n\nParameters: Key-value inputs to your code\nMetrics: Numeric values (can update over time)\nTags and Notes: Additional information about a run\nArtifacts: Files, data, and models\nSource: Name of the file used to launch the run\nVersion: The version of the source code\nRun: An instance of code that runs by MLflow\nExperiment: {Run, …, Run}\nStart & End Time: Start and end time of a run\n\n\n\n\nRuns and Artifacts Store\nMLFlow provides wide variety of storage option for logging runs and artifacts.\n\nMLflow Runs\n\nThey can be recorded to local files, to a SQLAlchemy compatible database, or remotely to a tracking server.\nMLflow uses backend store component for storing runs\nBackend store persists MLflow entities (runs, parameters, metrics, tags, notes, metadata, etc.)\nBackend store options:\n\nA file store backend - local file path\nA database-backed store - mysql, mssql, sqlite, or postgresql\nHTTP server (specified as https://my-server:5000), which is a server hosting an MLflow tracking server.\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, the MLflow Python API logs runs locally to files in an mlruns directory wherever you ran your program. You can then run mlflow ui to see the logged runs.\n\n\n\n\nMLflow Artifacts\n\nThey can be persisted to local files and a variety of remote file storage solutions.\nMLflow uses artifact store component for storing artifacts\nArtifact store persists artifacts (files, models, images, in-memory objects, or model summary, etc.)\nArtifact store options:\n\nLocal file path\nAmazon S3\nAzure Blob Storage\nGoogle Cloud Storage\nSFTP Server\nNFS"
  },
  {
    "objectID": "02_mlflow_intro.html#common-mlflow-configurations",
    "href": "02_mlflow_intro.html#common-mlflow-configurations",
    "title": "Data & AI Engineering Academy",
    "section": "Common MLflow configurations",
    "text": "Since the MLflow client can interface with a variety of backend and artifact storage configurations. We will look a three common scenarios:\n\n\n\nScenario 1 - MLflow on localhost\n\n\n\n\n\nScenario 2 - MLflow on localhost with backend store as an SQLAlchemy compatible database type: SQLite\n\n\n\n\n\nScenario 3 - Tracking server launched at localhost: mlflow server –backend-store-uri /workspace/mlruns"
  },
  {
    "objectID": "03_mlflow.html#what-you-will-learn",
    "href": "03_mlflow.html#what-you-will-learn",
    "title": "Data & AI Engineering Academy",
    "section": "What you will learn",
    "text": "How each component of MLflow helps address challenges of the ML lifecycle.\n\nHow to use MLflow Tracking to record and query experiments: code, data, config, and results.\nHow to use MLflow Models general format to send models to diverse deployment tools.\nHow to use MLflow Tracking UI to visually compare and contrast experimental runs with different tuning parameters and evaluate metrics."
  }
]