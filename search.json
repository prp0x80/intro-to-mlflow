[
  {
    "objectID": "01_ml_complexities.html#traditional-software-vs.-machine-learning",
    "href": "01_ml_complexities.html#traditional-software-vs.-machine-learning",
    "title": "Data & AI Engineering Academy",
    "section": "Traditional Software vs. Machine Learning",
    "text": "Developing machine learning applications is complex, and the complexity doesn’t necessarity strive from the fact that the theory behind the machine learning is difficult, or the math is difficult or the algorithm which are presented are difficult. Although there is some element of complexity, the machine learning frameworks makes it easier by abstracting away the details and exposing a simple class interface to initialise and train the model. In fact the default paramters gives pretty much a good baseline model to work with.\n\n\n\n\n\n\n\nTraditional Software\nMachine Learning\n\n\n\n\nGoal: Meet a functional specification\nGoal: Optimize metric (e.g. accuracy) Constantly experiment to improve it.\n\n\nQuality depends only on code\nQuality depends on input data and tuning parmeters\n\n\nTypically pick one software stack w/ fewer libraries and tools\nCompare + combine many libraries, models\n\n\nLimited deployment environments\nDiverse deployment environments"
  },
  {
    "objectID": "01_ml_complexities.html#machine-learning-lifecycle",
    "href": "01_ml_complexities.html#machine-learning-lifecycle",
    "title": "Data & AI Engineering Academy",
    "section": "Machine Learning Lifecycle",
    "text": "Following are four stages of a machine learning lifecycle, there can be other stages is between, but these are the paramount stages -\n\nData Ingestion - Depending on the nature of data you might use one of the many data technologies for staging the data e.g., Hadoop, Kafka, S3, Delta lake, etc.\nData Preparation - As per requirement and ease of use you might use a library in different language for preparing the data e.g., Spark, Pandas, Scikit-Learn, R, Java, etc.\nTraining - Depending on the problem and type of data you might use different libraries or framework for training the model e.g., Scikit-Learn, TensorFlow, PyTorch, Xgboost, etc.\nDeployment - Based on the type of model and how you want to serve the results there are many deployment options like Docker, Kubernetes, TensorFlow serving, Flask, etc.\n\n\n\n\n\nMLOps"
  },
  {
    "objectID": "01_ml_complexities.html#challenges-in-managing-machine-learning-lifecycle",
    "href": "01_ml_complexities.html#challenges-in-managing-machine-learning-lifecycle",
    "title": "Data & AI Engineering Academy",
    "section": "Challenges in managing Machine Learning lifecycle",
    "text": "Each stage has it’s own requirements and tools\nSome stages (data preparation and training) rely on tuning parameters\nEach stage has it’s own scaling requirements\nEnsuring the same model that yielded optimal performance is deployed\nGovernance and provenance - how the model evolved, who used it, when it was used so on and so forth.\n\nTo solve these challenges, MLflow, an open source project, simplifies the entire ML lifecycle. MLflow introduces simple abstractions to package reproducible projects, track results, encapsulate models that can be used with many existing tools, and central repository to share models, accelerating the ML lifecycle for organizations of any size."
  },
  {
    "objectID": "02_mlflow_intro.html#mlflow-components",
    "href": "02_mlflow_intro.html#mlflow-components",
    "title": "Data & AI Engineering Academy",
    "section": "MLflow Components",
    "text": "MLflow currently offers four components:\n\nMLflow Tracking - Record and query experiments: code, data, config, and results\nMLflow Projects - Package data science code in a format to reproduce runs on any platform\nMLflow Models - Deploy machine learning models in diverse serving environments\nMLflow Registry - Store, annotate, discover, and manage models in a central repository\n\n\n\n\n\n\n\nNote\n\n\n\nMLflow Models and MLflow Registry are not within the scope of this training.\n\n\n\nMLflow Tracking\nKey concepts in MLflow Tracking\n\nParameters: key-value inputs to your code\nMetrics: numeric values (can update over time)\nTags and Notes: information about a run\nArtifacts: files, data, and models\nSource: what code ran?\nVersion: what of the code?\nRun: an instance of code that runs by MLflow\nExperiment: {Run, …, Run}"
  },
  {
    "objectID": "03_mlflow.html#what-you-will-learn",
    "href": "03_mlflow.html#what-you-will-learn",
    "title": "Data & AI Engineering Academy",
    "section": "What you will learn",
    "text": "How each component of MLflow helps address challenges of the ML lifecycle.\n\nHow to use MLflow Tracking to record and query experiments: code, data, config, and results.\nHow to use MLflow Models general format to send models to diverse deployment tools.\nHow to use MLflow Tracking UI to visually compare and contrast experimental runs with different tuning parameters and evaluate metrics."
  }
]