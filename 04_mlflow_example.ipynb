{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: MLflow in Practice\n",
    "execute:\n",
    "  echo: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJPtF4u3EB8x"
   },
   "source": [
    "## Training employee attrition detection model\n",
    "\n",
    "**Objective**<br/>\n",
    "Predict if an employee is likely to quit and identify the factors responsible - to allow HR to intervene on time and remedy the situation to prevent attrition.\n",
    "\n",
    "> While some level of attrition in a company is inevitable, minimizing it and being prepared for the cases that cannot be helped will significantly help improve the operations of most businesses.\n",
    "\n",
    "**Data**<br/>\n",
    "The data set presents an employee survey from IBM, indicating if there is attrition or not. The data set contains approximately 1500 entries. Given the limited size of the data set, the model should only be expected to provide modest improvement in indentification of attrition vs a random allocation of probability of attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHJTS82O--Li"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9fjZOfsZNej"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXpgVMc0A0UE"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGgwPd31X8o7"
   },
   "outputs": [],
   "source": [
    "def load_csv_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads the csv file from path and returns pandas dataframe\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(path)\n",
    "        return data\n",
    "    except:\n",
    "        raise Exception(f\"Error while loading the data from {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YliSRhRgA4QI"
   },
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4ZB5UAxZXGH"
   },
   "outputs": [],
   "source": [
    "def split_data(\n",
    "    df: pd.DataFrame, test_size: float = 0.2, random_state: int = 42\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Splits the input data and returns training and test sets\"\"\"\n",
    "    drop_columns = [\n",
    "        \"EmployeeNumber\",\n",
    "        \"EmployeeCount\",\n",
    "        \"Over18\",\n",
    "        \"StandardHours\",\n",
    "        \"Attrition\",\n",
    "    ]\n",
    "    label_column = \"Attrition\"\n",
    "    features = df.drop(columns=drop_columns)\n",
    "    labels = df[label_column]\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features,\n",
    "        labels,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=labels,\n",
    "    )\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu1M_GGaA9si"
   },
   "source": [
    "#### Training\n",
    "Using Multilayer perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbcQjoXFZaOh"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_features: pd.DataFrame,\n",
    "    train_labels: pd.DataFrame,\n",
    "    random_state: int = 42,\n",
    "    **kwargs,\n",
    ") -> Tuple[LabelEncoder, Pipeline]:\n",
    "    \"\"\"Preprocesses the data and trains a model using sklearn pipeline\"\"\"\n",
    "    # label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(train_labels.values)\n",
    "    train_labels = label_encoder.transform(train_labels)\n",
    "    # pipeline\n",
    "    categorical_columns = [\n",
    "        \"BusinessTravel\",\n",
    "        \"Department\",\n",
    "        \"Education\",\n",
    "        \"EducationField\",\n",
    "        \"EnvironmentSatisfaction\",\n",
    "        \"Gender\",\n",
    "        \"JobInvolvement\",\n",
    "        \"JobLevel\",\n",
    "        \"JobRole\",\n",
    "        \"JobSatisfaction\",\n",
    "        \"MaritalStatus\",\n",
    "        \"OverTime\",\n",
    "        \"PerformanceRating\",\n",
    "        \"RelationshipSatisfaction\",\n",
    "        \"StockOptionLevel\",\n",
    "        \"WorkLifeBalance\",\n",
    "    ]\n",
    "    numerical_columns = train_features.select_dtypes(include=\"int64\").columns\n",
    "    transformers = [\n",
    "        (\"one_hot_encoder\", OneHotEncoder(), categorical_columns),\n",
    "        (\"scaler\", StandardScaler(), numerical_columns),\n",
    "    ]\n",
    "    preprocessing = ColumnTransformer(transformers=transformers)\n",
    "    classifier = MLPClassifier(\n",
    "        max_iter=kwargs.get(\"max_iter\", 500),\n",
    "        activation=kwargs.get(\"activation\", \"tanh\"),\n",
    "        solver=kwargs.get(\"solver\", \"sgd\"),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    model = Pipeline(\n",
    "        steps=[(\"preprocessing\", preprocessing), (\"classifier\", classifier)]\n",
    "    )\n",
    "    # model building - fit\n",
    "    model.fit(train_features, train_labels)\n",
    "    return label_encoder, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKgcsavK_8IG"
   },
   "source": [
    "#### Metrics\n",
    "\n",
    "**Accuracy**\n",
    "* Proportion of true results among the total number of cases\n",
    "* Accuracy is a valid choice of evaluation for classification problems which are well balanced and not skewed or No class imbalance\n",
    "\n",
    "**Precision**\n",
    "* Proportion of predicted positives are truly positives\n",
    "* Precision is a valid choice of evaluation metric when we want to be very sure of our prediction\n",
    "\n",
    "**Recall**\n",
    "* What proportion of actual Positives is correctly classified?\n",
    "* Recall is a valid choice of evaluation metric when we want to capture as many positives as possible\n",
    "* For example: If we are building a system to predict if a person has cancer or not, we want to capture the disease even if we are not very sure.\n",
    "\n",
    "**F1-score**\n",
    "* The F1 score is a number between 0 and 1 and is the harmonic mean of precision and recall\n",
    "* We use this when we want to have a model with both good precision and recall \n",
    "* If you are a police inspector and you want to catch criminals, you want to be sure that the person you catch is a criminal (Precision) and you also want to capture as many criminals (Recall) as possible. The F1 score manages this tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNIJAMs0Zdmt"
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: Pipeline,\n",
    "    label_encoder: LabelEncoder,\n",
    "    test_features: pd.DataFrame,\n",
    "    test_labels: pd.DataFrame,\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Evaluates the trained model using the held out test set\"\"\"\n",
    "    predictions = model.predict(test_features)\n",
    "    test_labels = label_encoder.transform(test_labels)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    cm = confusion_matrix(test_labels, predictions)\n",
    "    plot_confusion_matrix(\n",
    "        model, test_features, test_labels, display_labels=label_encoder.classes_\n",
    "    )\n",
    "    return accuracy, precision, recall, f1, cm, plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t232VpmYBRuV"
   },
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNvCtCIArVgx"
   },
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name, **parameters):\n",
    "    \"\"\"Runs all the steps and logs experiment parameters using mlflow\"\"\"\n",
    "    with mlflow.start_run(run_name=experiment_name) as run:\n",
    "        run_id = run.info.run_uuid\n",
    "        experiment_id = run.info.experiment_id\n",
    "        print(f\"\\nRun Id\", run_id)\n",
    "        print(f\"Experiment Id\", experiment_id)\n",
    "        data = load_csv_data(\"https://tinyurl.com/ibmhrattrition\")\n",
    "        train_features, test_features, train_labels, test_labels = split_data(data)\n",
    "        label_encoder, model = train(train_features, train_labels, **parameters)\n",
    "        mlflow.sklearn.log_model(model, \"hr-attrition-model\")\n",
    "        mlflow.log_params(parameters)\n",
    "        accuracy, precision, recall, f1, cm, plt_cm = evaluate(\n",
    "            model, label_encoder, test_features, test_labels\n",
    "        )\n",
    "        tp = cm[0][0]\n",
    "        tn = cm[1][1]\n",
    "        fp = cm[0][1]\n",
    "        fn = cm[1][0]\n",
    "        mlflow.log_metric(\"TP\", tp)\n",
    "        mlflow.log_metric(\"TN\", tn)\n",
    "        mlflow.log_metric(\"FP\", fp)\n",
    "        mlflow.log_metric(\"FN\", fn)\n",
    "        print(\"accuracy_score\", accuracy)\n",
    "        print(\"precision_score\", precision)\n",
    "        print(\"recall_score\", recall)\n",
    "        print(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"accuracy_score\", accuracy)\n",
    "        mlflow.log_metric(\"precision_score\", precision)\n",
    "        mlflow.log_metric(\"recall_score\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        fig_name = \"confusion-matrix.png\"\n",
    "        plt_cm.savefig(fig_name)\n",
    "        mlflow.log_artifact(fig_name, \"confusion-matrix-plot\")\n",
    "        return run_id, experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "s5ECaq4GhJMt",
    "outputId": "704a6c03-b8a3-4acb-af4f-0b817574ddea"
   },
   "outputs": [],
   "source": [
    "# change parameters and run experiments\n",
    "run_experiment(\n",
    "    \"hr-attrition-experiment\", max_iter=500, activation=\"relu\", solver=\"adam\"\n",
    ")\n",
    "# run_experiment(\"hr-attrition-experiment\", max_iter=1000, activation=\"relu\", solver=\"adam\")\n",
    "# run_experiment(\"hr-attrition-experiment\", max_iter=500, activation=\"relu\", solver=\"sgd\")\n",
    "# run_experiment(\"hr-attrition-experiment\", max_iter=1000, activation=\"relu\", solver=\"sgd\")\n",
    "# run_experiment(\"hr-attrition-experiment\", max_iter=500, activation=\"tanh\", solver=\"sgd\")\n",
    "# run_experiment(\"hr-attrition-experiment\", max_iter=500, activation=\"tanh\", solver=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmwj9-S_Fiju"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LLn50sDEZt_"
   },
   "outputs": [],
   "source": [
    "data = load_csv_data(\"https://tinyurl.com/ibmhrattrition\")\n",
    "train_features, test_features, train_labels, test_labels = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "oAPhG2aA22RN",
    "outputId": "33eab4c4-f4c7-4999-a1d5-a5b29a03a7cd"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kG5zeXLXyfM"
   },
   "outputs": [],
   "source": [
    "def predict(features):\n",
    "    run_id = \"72a2690bd0c24316984f4e2f9e49f3bd\"\n",
    "    logged_model = f\"file:///content/mlruns/0/{run_id}/artifacts/hr-attrition-model\"\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "    response = loaded_model.predict(pd.DataFrame(features))\n",
    "    return \"No\" if response[0] == 0 else \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "IP1hagqY3apW",
    "outputId": "623ed217-6797-4ac1-dad6-fe51d68de518"
   },
   "outputs": [],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "VEBmWRLaFAzK",
    "outputId": "318c1efa-2ce4-4b28-8216-c1af1f671d6c"
   },
   "outputs": [],
   "source": [
    "sample_features = test_features.loc[[1023]]\n",
    "sample_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Eru23rO3FyEn",
    "outputId": "d30cd586-de53-4f7c-d214-f9b01569654b"
   },
   "outputs": [],
   "source": [
    "predict(sample_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEcxsqF43u89",
    "outputId": "a46e9b85-2dd0-4a95-df56-80824edc3407"
   },
   "outputs": [],
   "source": [
    "test_labels.loc[[1023]]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct  4 2022, 14:00:32) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
